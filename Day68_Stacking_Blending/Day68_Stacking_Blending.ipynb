{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPzCs0Kz1IaqGzNSjb1TS8w"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# üß† Stacking (Stacked Generalization)\n","---\n","\n","## üìå Definition\n","Stacking is an **ensemble learning technique** where:\n","- Multiple base models are trained\n","- Their predictions are used as features\n","- A meta-model learns how to combine them\n","\n","Also called:\n","- Stacked Generalization\n","- Level-0 ‚Üí Level-1 learning\n","\n","---\n","\n","## üî• Why Stacking Exists\n","Simple ensembles like:\n","- Voting\n","- Averaging\n","\n","Assume all models are equally useful.\n","\n","Stacking instead:\n","> Learns optimal combination automatically\n","\n","---\n","\n","## üÜö Voting vs Stacking\n","\n","### Voting\n","- Mean (regression)\n","- Majority vote (classification)\n","- No learning\n","\n","### Stacking\n","- Trains another model\n","- Learns model relationships\n","- Often higher accuracy\n","\n","---\n","\n","## üß± Architecture\n","\n","```\n","Input Features\n","   ‚Üì\n","Base Models (Level-0)\n","   ‚Üì\n","Predictions as Features\n","   ‚Üì\n","Meta Model (Level-1)\n","   ‚Üì\n","Final Prediction\n","```\n","\n","---\n","\n","## üß™ Example Dataset\n","Features:\n","- CGPA\n","- IQ\n","\n","Target:\n","- Salary\n","\n","---\n","\n","## ‚öôÔ∏è Basic Workflow\n","\n","### Step 1 ‚Äî Train Base Models\n","Examples:\n","- Linear Regression\n","- Random Forest\n","- Decision Tree\n","- KNN\n","\n","---\n","\n","### Step 2 ‚Äî Generate Meta Dataset\n","\n","For each sample:\n","\n","| LR | RF | DT | Actual |\n","|----|----|----|--------|\n","\n","This becomes training data for meta-model.\n","\n","---\n","\n","### Step 3 ‚Äî Train Meta Model\n","Common choices:\n","- Logistic Regression\n","- Linear Regression\n","- Random Forest\n","\n","Meta-model learns:\n","- Which model to trust\n","- When to trust it\n","\n","---\n","\n","### Step 4 ‚Äî Prediction\n","For new input:\n","1. Get base predictions\n","2. Feed into meta-model\n","3. Output final prediction\n","\n","---\n","\n","## ‚ö†Ô∏è Core Problem ‚Äî Data Leakage\n","\n","If:\n","- Base models trained on full data\n","- Meta-model trained on same predictions\n","\n","Then:\n","‚ùå Overfitting\n","‚ùå Unrealistic performance\n","\n","---\n","\n","## üõ†Ô∏è Solutions to Leakage\n","\n","### 1Ô∏è‚É£ Holdout Stacking (Blending)\n","Split data:\n","\n","```\n","Train ‚Üí Base models\n","Validation ‚Üí Meta model\n","```\n","\n","Simple but wastes data.\n","\n","---\n","\n","### 2Ô∏è‚É£ K-Fold Stacking ‚≠ê (Industry Standard)\n","\n","Steps:\n","1. Split training data into K folds\n","2. For each fold:\n","   - Train on K-1 folds\n","   - Predict on remaining fold\n","3. Combine predictions\n","4. Train meta-model on combined predictions\n","\n","This ensures:\n","‚úî No leakage  \n","‚úî Full data usage  \n","\n","---\n","\n","## üßÆ Training Cost\n","\n","If:\n","- M base models\n","- K folds\n","\n","Total base trainings:\n","```\n","M √ó K\n","```\n","\n","Example:\n","- 3 models √ó 5 folds = 15 trainings\n","\n","---\n","\n","## üîÅ Retraining Step (Often Missed)\n","\n","After meta-model training:\n","\n","You must:\n","- Retrain base models on full training data\n","\n","Why?\n","Because inference should use maximum data.\n","\n","---\n","\n","## üß† Blending vs Stacking\n","\n","| Feature | Blending | Stacking |\n","|--------|----------|---------|\n","| Split | Holdout | K-fold |\n","| Data efficiency | Low | High |\n","| Complexity | Low | Higher |\n","| Industry usage | Medium | High |\n","\n","---\n","\n","## üß© Differences from Bagging & Boosting\n","\n","| Method | Idea |\n","|--------|------|\n","| Bagging | Parallel resampling |\n","| Boosting | Sequential correction |\n","| Stacking | Meta learning |\n","\n","Key difference:\n","Stacking learns combination explicitly.\n","\n","---\n","\n","## üß¨ Advanced Stacking\n","\n","### Multi-layer Stacking\n","```\n","Layer 1 ‚Üí Many models\n","Layer 2 ‚Üí Fewer models\n","Layer 3 ‚Üí Meta model\n","```\n","\n","Used in:\n","- Kaggle winners\n","- AutoML\n","\n","---\n","\n","### Real Competition Example\n","Winning pipelines often use:\n","- 50+ base models\n","- Multiple stacking layers\n","- Neural net meta-models\n","\n","---\n","\n","## üß™ sklearn Implementation\n","\n","### Basic Example\n","\n","```python\n","from sklearn.ensemble import StackingClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","\n","base_models = [\n","    (\"rf\", RandomForestClassifier()),\n","    (\"svm\", SVC(probability=True))\n","]\n","\n","meta_model = LogisticRegression()\n","\n","stack = StackingClassifier(\n","    estimators=base_models,\n","    final_estimator=meta_model,\n","    cv=5\n",")\n","\n","stack.fit(X_train, y_train)\n","```\n","\n","---\n","\n","## üîß Important Parameters\n","\n","### `cv`\n","- Number of folds\n","- Prevents leakage\n","\n","---\n","\n","### `passthrough=True`\n","Adds original features to meta model.\n","\n","Without:\n","Meta uses only predictions.\n","\n","With:\n","Meta uses:\n","- Predictions\n","- Original features\n","\n","---\n","\n","### Meta-model choice\n","Best options:\n","- Linear models (stable)\n","- Logistic regression\n","- LightGBM (advanced)\n","\n","Avoid:\n","- Overly complex meta-models initially\n","\n","---\n","\n","## üìà When Stacking Works Best\n","\n","‚úî Diverse base models  \n","‚úî Medium datasets  \n","‚úî Competition settings  \n","‚úî High accuracy needed  \n","\n","---\n","\n","## ‚ùå When Stacking Fails\n","\n","- Small datasets\n","- Highly correlated models\n","- Poor CV design\n","- Leakage mistakes\n","\n","---\n","\n","## üß† Best Practices\n","\n","‚úî Use diverse algorithms  \n","‚úî Normalize probabilities  \n","‚úî Use stratified folds  \n","‚úî Keep meta-model simple first  \n","‚úî Tune later  \n","\n","---\n","\n","## üö´ Common Mistakes\n","\n","‚ùå Training meta-model on same data  \n","‚ùå Using identical base models  \n","‚ùå Ignoring probability calibration  \n","‚ùå No cross-validation  \n","\n","---\n","\n","## ‚ö° Performance Tips\n","\n","- Use out-of-fold predictions\n","- Blend with weighted averaging\n","- Use stacking + blending hybrid\n","- Use calibration (Platt scaling)\n","\n","---\n","\n","## üìä Real-World Use Cases\n","\n","- Kaggle competitions\n","- Credit scoring\n","- Medical prediction\n","- Ad ranking\n","- Fraud detection\n","\n","---\n","\n","## üéØ Interview Questions\n","\n","**Q: What is stacking?**  \n","Ensemble with meta-learner.\n","\n","**Q: Why better than voting?**  \n","Learns optimal combination.\n","\n","**Q: Biggest risk?**  \n","Data leakage.\n","\n","**Q: Solution?**  \n","K-fold stacking.\n","\n","**Q: Blending vs stacking?**  \n","Holdout vs CV.\n","\n","---\n"],"metadata":{"id":"82fgEg3I19do"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"CnZP1-47bbjV"},"outputs":[],"source":["import numpy as np\n","import pandas as pd"]},{"cell_type":"code","source":["df = pd.read_csv('breast_cancer.csv')\n","df.sample(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":383},"id":"BTDe1a-wfUNn","executionInfo":{"status":"ok","timestamp":1771934331217,"user_tz":-330,"elapsed":184,"user":{"displayName":"Arnav Tomar","userId":"05362157737552244045"}},"outputId":"8dd2e926-c177-4a57-a459-4942d50048cc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                                                                                                                                                                               569  \\\n","12.300 15.90 78.83  463.7  0.08080 0.07253 0.03844 0.01654 0.1667 0.05474 0.2382 0.8355 1.687 18.32 0.005996 0.022120 0.021170 0.006433 0.02025 0.001725 13.350 19.59 86.65  546.7  0.1096 0.16500 0.1423  0.04815   \n","14.970 19.76 95.50  690.2  0.08421 0.05352 0.01947 0.01939 0.1515 0.05266 0.1840 1.0650 1.286 16.64 0.003634 0.007983 0.008268 0.006432 0.01924 0.001520 15.980 25.82 102.30 782.1  0.1045 0.09995 0.0775  0.05754   \n","13.210 25.25 84.10  537.9  0.08791 0.05205 0.02772 0.02068 0.1619 0.05584 0.2084 1.3500 1.314 17.58 0.005768 0.008082 0.015100 0.006451 0.01347 0.001828 14.350 34.23 91.29  632.9  0.1289 0.10630 0.1390  0.06005   \n","18.810 19.98 120.90 1102.0 0.08923 0.05884 0.08020 0.05843 0.1550 0.04996 0.3283 0.8280 2.363 36.74 0.007571 0.011140 0.026230 0.014630 0.01930 0.001676 19.960 24.30 129.00 1236.0 0.1243 0.11600 0.2210  0.12940   \n","11.450 20.97 73.81  401.5  0.11020 0.09362 0.04591 0.02233 0.1842 0.07005 0.3251 2.1740 2.077 24.62 0.010370 0.017060 0.025860 0.007506 0.01816 0.003976 13.110 32.16 84.53  525.1  0.1557 0.16760 0.1755  0.06127   \n","13.660 15.15 88.27  580.6  0.08268 0.07548 0.04249 0.02471 0.1792 0.05897 0.1402 0.5417 1.101 11.35 0.005212 0.029840 0.024430 0.008356 0.01818 0.004868 14.540 19.64 97.96  657.0  0.1275 0.31040 0.2569  0.10540   \n","11.540 14.44 74.65  402.9  0.09984 0.11200 0.06737 0.02594 0.1818 0.06782 0.2784 1.7680 1.628 20.86 0.012150 0.041120 0.055530 0.014940 0.01840 0.005512 12.260 19.68 78.78  457.8  0.1345 0.21180 0.1797  0.06918   \n","9.029  17.33 58.79  250.5  0.10660 0.14130 0.31300 0.04375 0.2111 0.08046 0.3274 1.1940 1.885 17.67 0.009549 0.086060 0.303800 0.033220 0.04197 0.009559 10.310 22.65 65.50  324.7  0.1482 0.43650 1.2520  0.17500   \n","8.671  14.45 54.42  227.2  0.09138 0.04276 0.00000 0.00000 0.1722 0.06724 0.2204 0.7873 1.435 11.36 0.009172 0.008007 0.000000 0.000000 0.02711 0.003399 9.262  17.04 58.36  259.2  0.1162 0.07057 0.0000  0.00000   \n","15.610 19.38 100.00 758.6  0.07840 0.05616 0.04209 0.02847 0.1547 0.05443 0.2298 0.9988 1.534 22.18 0.002826 0.009105 0.013110 0.005174 0.01013 0.001345 17.910 31.67 115.90 988.6  0.1084 0.18070 0.2260  0.08568   \n","\n","                                                                                                                                                                                                               30  \\\n","12.300 15.90 78.83  463.7  0.08080 0.07253 0.03844 0.01654 0.1667 0.05474 0.2382 0.8355 1.687 18.32 0.005996 0.022120 0.021170 0.006433 0.02025 0.001725 13.350 19.59 86.65  546.7  0.1096 0.16500 0.1423  0.2482   \n","14.970 19.76 95.50  690.2  0.08421 0.05352 0.01947 0.01939 0.1515 0.05266 0.1840 1.0650 1.286 16.64 0.003634 0.007983 0.008268 0.006432 0.01924 0.001520 15.980 25.82 102.30 782.1  0.1045 0.09995 0.0775  0.2646   \n","13.210 25.25 84.10  537.9  0.08791 0.05205 0.02772 0.02068 0.1619 0.05584 0.2084 1.3500 1.314 17.58 0.005768 0.008082 0.015100 0.006451 0.01347 0.001828 14.350 34.23 91.29  632.9  0.1289 0.10630 0.1390  0.2444   \n","18.810 19.98 120.90 1102.0 0.08923 0.05884 0.08020 0.05843 0.1550 0.04996 0.3283 0.8280 2.363 36.74 0.007571 0.011140 0.026230 0.014630 0.01930 0.001676 19.960 24.30 129.00 1236.0 0.1243 0.11600 0.2210  0.2567   \n","11.450 20.97 73.81  401.5  0.11020 0.09362 0.04591 0.02233 0.1842 0.07005 0.3251 2.1740 2.077 24.62 0.010370 0.017060 0.025860 0.007506 0.01816 0.003976 13.110 32.16 84.53  525.1  0.1557 0.16760 0.1755  0.2762   \n","13.660 15.15 88.27  580.6  0.08268 0.07548 0.04249 0.02471 0.1792 0.05897 0.1402 0.5417 1.101 11.35 0.005212 0.029840 0.024430 0.008356 0.01818 0.004868 14.540 19.64 97.96  657.0  0.1275 0.31040 0.2569  0.3387   \n","11.540 14.44 74.65  402.9  0.09984 0.11200 0.06737 0.02594 0.1818 0.06782 0.2784 1.7680 1.628 20.86 0.012150 0.041120 0.055530 0.014940 0.01840 0.005512 12.260 19.68 78.78  457.8  0.1345 0.21180 0.1797  0.2329   \n","9.029  17.33 58.79  250.5  0.10660 0.14130 0.31300 0.04375 0.2111 0.08046 0.3274 1.1940 1.885 17.67 0.009549 0.086060 0.303800 0.033220 0.04197 0.009559 10.310 22.65 65.50  324.7  0.1482 0.43650 1.2520  0.4228   \n","8.671  14.45 54.42  227.2  0.09138 0.04276 0.00000 0.00000 0.1722 0.06724 0.2204 0.7873 1.435 11.36 0.009172 0.008007 0.000000 0.000000 0.02711 0.003399 9.262  17.04 58.36  259.2  0.1162 0.07057 0.0000  0.2592   \n","15.610 19.38 100.00 758.6  0.07840 0.05616 0.04209 0.02847 0.1547 0.05443 0.2298 0.9988 1.534 22.18 0.002826 0.009105 0.013110 0.005174 0.01013 0.001345 17.910 31.67 115.90 988.6  0.1084 0.18070 0.2260  0.2683   \n","\n","                                                                                                                                                                                                           malignant  \\\n","12.300 15.90 78.83  463.7  0.08080 0.07253 0.03844 0.01654 0.1667 0.05474 0.2382 0.8355 1.687 18.32 0.005996 0.022120 0.021170 0.006433 0.02025 0.001725 13.350 19.59 86.65  546.7  0.1096 0.16500 0.1423    0.06306   \n","14.970 19.76 95.50  690.2  0.08421 0.05352 0.01947 0.01939 0.1515 0.05266 0.1840 1.0650 1.286 16.64 0.003634 0.007983 0.008268 0.006432 0.01924 0.001520 15.980 25.82 102.30 782.1  0.1045 0.09995 0.0775    0.06085   \n","13.210 25.25 84.10  537.9  0.08791 0.05205 0.02772 0.02068 0.1619 0.05584 0.2084 1.3500 1.314 17.58 0.005768 0.008082 0.015100 0.006451 0.01347 0.001828 14.350 34.23 91.29  632.9  0.1289 0.10630 0.1390    0.06788   \n","18.810 19.98 120.90 1102.0 0.08923 0.05884 0.08020 0.05843 0.1550 0.04996 0.3283 0.8280 2.363 36.74 0.007571 0.011140 0.026230 0.014630 0.01930 0.001676 19.960 24.30 129.00 1236.0 0.1243 0.11600 0.2210    0.05737   \n","11.450 20.97 73.81  401.5  0.11020 0.09362 0.04591 0.02233 0.1842 0.07005 0.3251 2.1740 2.077 24.62 0.010370 0.017060 0.025860 0.007506 0.01816 0.003976 13.110 32.16 84.53  525.1  0.1557 0.16760 0.1755    0.08851   \n","13.660 15.15 88.27  580.6  0.08268 0.07548 0.04249 0.02471 0.1792 0.05897 0.1402 0.5417 1.101 11.35 0.005212 0.029840 0.024430 0.008356 0.01818 0.004868 14.540 19.64 97.96  657.0  0.1275 0.31040 0.2569    0.09638   \n","11.540 14.44 74.65  402.9  0.09984 0.11200 0.06737 0.02594 0.1818 0.06782 0.2784 1.7680 1.628 20.86 0.012150 0.041120 0.055530 0.014940 0.01840 0.005512 12.260 19.68 78.78  457.8  0.1345 0.21180 0.1797    0.08134   \n","9.029  17.33 58.79  250.5  0.10660 0.14130 0.31300 0.04375 0.2111 0.08046 0.3274 1.1940 1.885 17.67 0.009549 0.086060 0.303800 0.033220 0.04197 0.009559 10.310 22.65 65.50  324.7  0.1482 0.43650 1.2520    0.11750   \n","8.671  14.45 54.42  227.2  0.09138 0.04276 0.00000 0.00000 0.1722 0.06724 0.2204 0.7873 1.435 11.36 0.009172 0.008007 0.000000 0.000000 0.02711 0.003399 9.262  17.04 58.36  259.2  0.1162 0.07057 0.0000    0.07848   \n","15.610 19.38 100.00 758.6  0.07840 0.05616 0.04209 0.02847 0.1547 0.05443 0.2298 0.9988 1.534 22.18 0.002826 0.009105 0.013110 0.005174 0.01013 0.001345 17.910 31.67 115.90 988.6  0.1084 0.18070 0.2260    0.06829   \n","\n","                                                                                                                                                                                                           benign  \n","12.300 15.90 78.83  463.7  0.08080 0.07253 0.03844 0.01654 0.1667 0.05474 0.2382 0.8355 1.687 18.32 0.005996 0.022120 0.021170 0.006433 0.02025 0.001725 13.350 19.59 86.65  546.7  0.1096 0.16500 0.1423       1  \n","14.970 19.76 95.50  690.2  0.08421 0.05352 0.01947 0.01939 0.1515 0.05266 0.1840 1.0650 1.286 16.64 0.003634 0.007983 0.008268 0.006432 0.01924 0.001520 15.980 25.82 102.30 782.1  0.1045 0.09995 0.0775       1  \n","13.210 25.25 84.10  537.9  0.08791 0.05205 0.02772 0.02068 0.1619 0.05584 0.2084 1.3500 1.314 17.58 0.005768 0.008082 0.015100 0.006451 0.01347 0.001828 14.350 34.23 91.29  632.9  0.1289 0.10630 0.1390       1  \n","18.810 19.98 120.90 1102.0 0.08923 0.05884 0.08020 0.05843 0.1550 0.04996 0.3283 0.8280 2.363 36.74 0.007571 0.011140 0.026230 0.014630 0.01930 0.001676 19.960 24.30 129.00 1236.0 0.1243 0.11600 0.2210       0  \n","11.450 20.97 73.81  401.5  0.11020 0.09362 0.04591 0.02233 0.1842 0.07005 0.3251 2.1740 2.077 24.62 0.010370 0.017060 0.025860 0.007506 0.01816 0.003976 13.110 32.16 84.53  525.1  0.1557 0.16760 0.1755       1  \n","13.660 15.15 88.27  580.6  0.08268 0.07548 0.04249 0.02471 0.1792 0.05897 0.1402 0.5417 1.101 11.35 0.005212 0.029840 0.024430 0.008356 0.01818 0.004868 14.540 19.64 97.96  657.0  0.1275 0.31040 0.2569       1  \n","11.540 14.44 74.65  402.9  0.09984 0.11200 0.06737 0.02594 0.1818 0.06782 0.2784 1.7680 1.628 20.86 0.012150 0.041120 0.055530 0.014940 0.01840 0.005512 12.260 19.68 78.78  457.8  0.1345 0.21180 0.1797       1  \n","9.029  17.33 58.79  250.5  0.10660 0.14130 0.31300 0.04375 0.2111 0.08046 0.3274 1.1940 1.885 17.67 0.009549 0.086060 0.303800 0.033220 0.04197 0.009559 10.310 22.65 65.50  324.7  0.1482 0.43650 1.2520       1  \n","8.671  14.45 54.42  227.2  0.09138 0.04276 0.00000 0.00000 0.1722 0.06724 0.2204 0.7873 1.435 11.36 0.009172 0.008007 0.000000 0.000000 0.02711 0.003399 9.262  17.04 58.36  259.2  0.1162 0.07057 0.0000       1  \n","15.610 19.38 100.00 758.6  0.07840 0.05616 0.04209 0.02847 0.1547 0.05443 0.2298 0.9988 1.534 22.18 0.002826 0.009105 0.013110 0.005174 0.01013 0.001345 17.910 31.67 115.90 988.6  0.1084 0.18070 0.2260       0  "],"text/html":["\n","  <div id=\"df-b2f5074a-ac56-4f7a-ae19-6cb483d94e2c\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th>569</th>\n","      <th>30</th>\n","      <th>malignant</th>\n","      <th>benign</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>12.300</th>\n","      <th>15.90</th>\n","      <th>78.83</th>\n","      <th>463.7</th>\n","      <th>0.08080</th>\n","      <th>0.07253</th>\n","      <th>0.03844</th>\n","      <th>0.01654</th>\n","      <th>0.1667</th>\n","      <th>0.05474</th>\n","      <th>0.2382</th>\n","      <th>0.8355</th>\n","      <th>1.687</th>\n","      <th>18.32</th>\n","      <th>0.005996</th>\n","      <th>0.022120</th>\n","      <th>0.021170</th>\n","      <th>0.006433</th>\n","      <th>0.02025</th>\n","      <th>0.001725</th>\n","      <th>13.350</th>\n","      <th>19.59</th>\n","      <th>86.65</th>\n","      <th>546.7</th>\n","      <th>0.1096</th>\n","      <th>0.16500</th>\n","      <th>0.1423</th>\n","      <td>0.04815</td>\n","      <td>0.2482</td>\n","      <td>0.06306</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>14.970</th>\n","      <th>19.76</th>\n","      <th>95.50</th>\n","      <th>690.2</th>\n","      <th>0.08421</th>\n","      <th>0.05352</th>\n","      <th>0.01947</th>\n","      <th>0.01939</th>\n","      <th>0.1515</th>\n","      <th>0.05266</th>\n","      <th>0.1840</th>\n","      <th>1.0650</th>\n","      <th>1.286</th>\n","      <th>16.64</th>\n","      <th>0.003634</th>\n","      <th>0.007983</th>\n","      <th>0.008268</th>\n","      <th>0.006432</th>\n","      <th>0.01924</th>\n","      <th>0.001520</th>\n","      <th>15.980</th>\n","      <th>25.82</th>\n","      <th>102.30</th>\n","      <th>782.1</th>\n","      <th>0.1045</th>\n","      <th>0.09995</th>\n","      <th>0.0775</th>\n","      <td>0.05754</td>\n","      <td>0.2646</td>\n","      <td>0.06085</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>13.210</th>\n","      <th>25.25</th>\n","      <th>84.10</th>\n","      <th>537.9</th>\n","      <th>0.08791</th>\n","      <th>0.05205</th>\n","      <th>0.02772</th>\n","      <th>0.02068</th>\n","      <th>0.1619</th>\n","      <th>0.05584</th>\n","      <th>0.2084</th>\n","      <th>1.3500</th>\n","      <th>1.314</th>\n","      <th>17.58</th>\n","      <th>0.005768</th>\n","      <th>0.008082</th>\n","      <th>0.015100</th>\n","      <th>0.006451</th>\n","      <th>0.01347</th>\n","      <th>0.001828</th>\n","      <th>14.350</th>\n","      <th>34.23</th>\n","      <th>91.29</th>\n","      <th>632.9</th>\n","      <th>0.1289</th>\n","      <th>0.10630</th>\n","      <th>0.1390</th>\n","      <td>0.06005</td>\n","      <td>0.2444</td>\n","      <td>0.06788</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>18.810</th>\n","      <th>19.98</th>\n","      <th>120.90</th>\n","      <th>1102.0</th>\n","      <th>0.08923</th>\n","      <th>0.05884</th>\n","      <th>0.08020</th>\n","      <th>0.05843</th>\n","      <th>0.1550</th>\n","      <th>0.04996</th>\n","      <th>0.3283</th>\n","      <th>0.8280</th>\n","      <th>2.363</th>\n","      <th>36.74</th>\n","      <th>0.007571</th>\n","      <th>0.011140</th>\n","      <th>0.026230</th>\n","      <th>0.014630</th>\n","      <th>0.01930</th>\n","      <th>0.001676</th>\n","      <th>19.960</th>\n","      <th>24.30</th>\n","      <th>129.00</th>\n","      <th>1236.0</th>\n","      <th>0.1243</th>\n","      <th>0.11600</th>\n","      <th>0.2210</th>\n","      <td>0.12940</td>\n","      <td>0.2567</td>\n","      <td>0.05737</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>11.450</th>\n","      <th>20.97</th>\n","      <th>73.81</th>\n","      <th>401.5</th>\n","      <th>0.11020</th>\n","      <th>0.09362</th>\n","      <th>0.04591</th>\n","      <th>0.02233</th>\n","      <th>0.1842</th>\n","      <th>0.07005</th>\n","      <th>0.3251</th>\n","      <th>2.1740</th>\n","      <th>2.077</th>\n","      <th>24.62</th>\n","      <th>0.010370</th>\n","      <th>0.017060</th>\n","      <th>0.025860</th>\n","      <th>0.007506</th>\n","      <th>0.01816</th>\n","      <th>0.003976</th>\n","      <th>13.110</th>\n","      <th>32.16</th>\n","      <th>84.53</th>\n","      <th>525.1</th>\n","      <th>0.1557</th>\n","      <th>0.16760</th>\n","      <th>0.1755</th>\n","      <td>0.06127</td>\n","      <td>0.2762</td>\n","      <td>0.08851</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>13.660</th>\n","      <th>15.15</th>\n","      <th>88.27</th>\n","      <th>580.6</th>\n","      <th>0.08268</th>\n","      <th>0.07548</th>\n","      <th>0.04249</th>\n","      <th>0.02471</th>\n","      <th>0.1792</th>\n","      <th>0.05897</th>\n","      <th>0.1402</th>\n","      <th>0.5417</th>\n","      <th>1.101</th>\n","      <th>11.35</th>\n","      <th>0.005212</th>\n","      <th>0.029840</th>\n","      <th>0.024430</th>\n","      <th>0.008356</th>\n","      <th>0.01818</th>\n","      <th>0.004868</th>\n","      <th>14.540</th>\n","      <th>19.64</th>\n","      <th>97.96</th>\n","      <th>657.0</th>\n","      <th>0.1275</th>\n","      <th>0.31040</th>\n","      <th>0.2569</th>\n","      <td>0.10540</td>\n","      <td>0.3387</td>\n","      <td>0.09638</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>11.540</th>\n","      <th>14.44</th>\n","      <th>74.65</th>\n","      <th>402.9</th>\n","      <th>0.09984</th>\n","      <th>0.11200</th>\n","      <th>0.06737</th>\n","      <th>0.02594</th>\n","      <th>0.1818</th>\n","      <th>0.06782</th>\n","      <th>0.2784</th>\n","      <th>1.7680</th>\n","      <th>1.628</th>\n","      <th>20.86</th>\n","      <th>0.012150</th>\n","      <th>0.041120</th>\n","      <th>0.055530</th>\n","      <th>0.014940</th>\n","      <th>0.01840</th>\n","      <th>0.005512</th>\n","      <th>12.260</th>\n","      <th>19.68</th>\n","      <th>78.78</th>\n","      <th>457.8</th>\n","      <th>0.1345</th>\n","      <th>0.21180</th>\n","      <th>0.1797</th>\n","      <td>0.06918</td>\n","      <td>0.2329</td>\n","      <td>0.08134</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9.029</th>\n","      <th>17.33</th>\n","      <th>58.79</th>\n","      <th>250.5</th>\n","      <th>0.10660</th>\n","      <th>0.14130</th>\n","      <th>0.31300</th>\n","      <th>0.04375</th>\n","      <th>0.2111</th>\n","      <th>0.08046</th>\n","      <th>0.3274</th>\n","      <th>1.1940</th>\n","      <th>1.885</th>\n","      <th>17.67</th>\n","      <th>0.009549</th>\n","      <th>0.086060</th>\n","      <th>0.303800</th>\n","      <th>0.033220</th>\n","      <th>0.04197</th>\n","      <th>0.009559</th>\n","      <th>10.310</th>\n","      <th>22.65</th>\n","      <th>65.50</th>\n","      <th>324.7</th>\n","      <th>0.1482</th>\n","      <th>0.43650</th>\n","      <th>1.2520</th>\n","      <td>0.17500</td>\n","      <td>0.4228</td>\n","      <td>0.11750</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8.671</th>\n","      <th>14.45</th>\n","      <th>54.42</th>\n","      <th>227.2</th>\n","      <th>0.09138</th>\n","      <th>0.04276</th>\n","      <th>0.00000</th>\n","      <th>0.00000</th>\n","      <th>0.1722</th>\n","      <th>0.06724</th>\n","      <th>0.2204</th>\n","      <th>0.7873</th>\n","      <th>1.435</th>\n","      <th>11.36</th>\n","      <th>0.009172</th>\n","      <th>0.008007</th>\n","      <th>0.000000</th>\n","      <th>0.000000</th>\n","      <th>0.02711</th>\n","      <th>0.003399</th>\n","      <th>9.262</th>\n","      <th>17.04</th>\n","      <th>58.36</th>\n","      <th>259.2</th>\n","      <th>0.1162</th>\n","      <th>0.07057</th>\n","      <th>0.0000</th>\n","      <td>0.00000</td>\n","      <td>0.2592</td>\n","      <td>0.07848</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>15.610</th>\n","      <th>19.38</th>\n","      <th>100.00</th>\n","      <th>758.6</th>\n","      <th>0.07840</th>\n","      <th>0.05616</th>\n","      <th>0.04209</th>\n","      <th>0.02847</th>\n","      <th>0.1547</th>\n","      <th>0.05443</th>\n","      <th>0.2298</th>\n","      <th>0.9988</th>\n","      <th>1.534</th>\n","      <th>22.18</th>\n","      <th>0.002826</th>\n","      <th>0.009105</th>\n","      <th>0.013110</th>\n","      <th>0.005174</th>\n","      <th>0.01013</th>\n","      <th>0.001345</th>\n","      <th>17.910</th>\n","      <th>31.67</th>\n","      <th>115.90</th>\n","      <th>988.6</th>\n","      <th>0.1084</th>\n","      <th>0.18070</th>\n","      <th>0.2260</th>\n","      <td>0.08568</td>\n","      <td>0.2683</td>\n","      <td>0.06829</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2f5074a-ac56-4f7a-ae19-6cb483d94e2c')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-b2f5074a-ac56-4f7a-ae19-6cb483d94e2c button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-b2f5074a-ac56-4f7a-ae19-6cb483d94e2c');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"569\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04821319023070576,\n        \"min\": 0.0,\n        \"max\": 0.175,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.0,\n          0.05754,\n          0.1054\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"30\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.057430305588600176,\n        \"min\": 0.2329,\n        \"max\": 0.4228,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.2592,\n          0.2646,\n          0.3387\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"malignant\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.018736566862095565,\n        \"min\": 0.05737,\n        \"max\": 0.1175,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.07848,\n          0.06085,\n          0.09638\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"benign\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["X = df.drop(columns=['benign'])\n","y = df['benign']"],"metadata":{"id":"UmBTc4rMfXYD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=8)\n","print(X_train.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uib9M_iLfo3D","executionInfo":{"status":"ok","timestamp":1771934345073,"user_tz":-330,"elapsed":17,"user":{"displayName":"Arnav Tomar","userId":"05362157737552244045"}},"outputId":"f3044ca7-4d31-4b9c-cac4-ec42620be300"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(455, 3)\n"]}]},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import GradientBoostingClassifier"],"metadata":{"id":"xYhAVkIBfsC-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["estimators = [\n","    ('rf', RandomForestClassifier(n_estimators=10, random_state=42)),\n","    ('knn', KNeighborsClassifier(n_neighbors=10)),\n","    ('gbdt',GradientBoostingClassifier())\n","]"],"metadata":{"id":"ME8sDniRfwVO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.ensemble import StackingClassifier\n","\n","clf = StackingClassifier(\n","    estimators=estimators,\n","    final_estimator=LogisticRegression(),\n","    cv=10\n",")"],"metadata":{"id":"lOro4bB_fzOU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["clf.fit(X_train, y_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":214},"id":"zAqUm6hif7OW","executionInfo":{"status":"ok","timestamp":1771934350892,"user_tz":-330,"elapsed":2284,"user":{"displayName":"Arnav Tomar","userId":"05362157737552244045"}},"outputId":"38972e5f-6b98-40a0-c4b9-e2cc267cae1b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["StackingClassifier(cv=10,\n","                   estimators=[('rf',\n","                                RandomForestClassifier(n_estimators=10,\n","                                                       random_state=42)),\n","                               ('knn', KNeighborsClassifier(n_neighbors=10)),\n","                               ('gbdt', GradientBoostingClassifier())],\n","                   final_estimator=LogisticRegression())"],"text/html":["<style>#sk-container-id-2 {\n","  /* Definition of color scheme common for light and dark mode */\n","  --sklearn-color-text: #000;\n","  --sklearn-color-text-muted: #666;\n","  --sklearn-color-line: gray;\n","  /* Definition of color scheme for unfitted estimators */\n","  --sklearn-color-unfitted-level-0: #fff5e6;\n","  --sklearn-color-unfitted-level-1: #f6e4d2;\n","  --sklearn-color-unfitted-level-2: #ffe0b3;\n","  --sklearn-color-unfitted-level-3: chocolate;\n","  /* Definition of color scheme for fitted estimators */\n","  --sklearn-color-fitted-level-0: #f0f8ff;\n","  --sklearn-color-fitted-level-1: #d4ebff;\n","  --sklearn-color-fitted-level-2: #b3dbfd;\n","  --sklearn-color-fitted-level-3: cornflowerblue;\n","\n","  /* Specific color for light theme */\n","  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n","  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-icon: #696969;\n","\n","  @media (prefers-color-scheme: dark) {\n","    /* Redefinition of color scheme for dark theme */\n","    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n","    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-icon: #878787;\n","  }\n","}\n","\n","#sk-container-id-2 {\n","  color: var(--sklearn-color-text);\n","}\n","\n","#sk-container-id-2 pre {\n","  padding: 0;\n","}\n","\n","#sk-container-id-2 input.sk-hidden--visually {\n","  border: 0;\n","  clip: rect(1px 1px 1px 1px);\n","  clip: rect(1px, 1px, 1px, 1px);\n","  height: 1px;\n","  margin: -1px;\n","  overflow: hidden;\n","  padding: 0;\n","  position: absolute;\n","  width: 1px;\n","}\n","\n","#sk-container-id-2 div.sk-dashed-wrapped {\n","  border: 1px dashed var(--sklearn-color-line);\n","  margin: 0 0.4em 0.5em 0.4em;\n","  box-sizing: border-box;\n","  padding-bottom: 0.4em;\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","#sk-container-id-2 div.sk-container {\n","  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n","     but bootstrap.min.css set `[hidden] { display: none !important; }`\n","     so we also need the `!important` here to be able to override the\n","     default hidden behavior on the sphinx rendered scikit-learn.org.\n","     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n","  display: inline-block !important;\n","  position: relative;\n","}\n","\n","#sk-container-id-2 div.sk-text-repr-fallback {\n","  display: none;\n","}\n","\n","div.sk-parallel-item,\n","div.sk-serial,\n","div.sk-item {\n","  /* draw centered vertical line to link estimators */\n","  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n","  background-size: 2px 100%;\n","  background-repeat: no-repeat;\n","  background-position: center center;\n","}\n","\n","/* Parallel-specific style estimator block */\n","\n","#sk-container-id-2 div.sk-parallel-item::after {\n","  content: \"\";\n","  width: 100%;\n","  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n","  flex-grow: 1;\n","}\n","\n","#sk-container-id-2 div.sk-parallel {\n","  display: flex;\n","  align-items: stretch;\n","  justify-content: center;\n","  background-color: var(--sklearn-color-background);\n","  position: relative;\n","}\n","\n","#sk-container-id-2 div.sk-parallel-item {\n","  display: flex;\n","  flex-direction: column;\n","}\n","\n","#sk-container-id-2 div.sk-parallel-item:first-child::after {\n","  align-self: flex-end;\n","  width: 50%;\n","}\n","\n","#sk-container-id-2 div.sk-parallel-item:last-child::after {\n","  align-self: flex-start;\n","  width: 50%;\n","}\n","\n","#sk-container-id-2 div.sk-parallel-item:only-child::after {\n","  width: 0;\n","}\n","\n","/* Serial-specific style estimator block */\n","\n","#sk-container-id-2 div.sk-serial {\n","  display: flex;\n","  flex-direction: column;\n","  align-items: center;\n","  background-color: var(--sklearn-color-background);\n","  padding-right: 1em;\n","  padding-left: 1em;\n","}\n","\n","\n","/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n","clickable and can be expanded/collapsed.\n","- Pipeline and ColumnTransformer use this feature and define the default style\n","- Estimators will overwrite some part of the style using the `sk-estimator` class\n","*/\n","\n","/* Pipeline and ColumnTransformer style (default) */\n","\n","#sk-container-id-2 div.sk-toggleable {\n","  /* Default theme specific background. It is overwritten whether we have a\n","  specific estimator or a Pipeline/ColumnTransformer */\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","/* Toggleable label */\n","#sk-container-id-2 label.sk-toggleable__label {\n","  cursor: pointer;\n","  display: flex;\n","  width: 100%;\n","  margin-bottom: 0;\n","  padding: 0.5em;\n","  box-sizing: border-box;\n","  text-align: center;\n","  align-items: start;\n","  justify-content: space-between;\n","  gap: 0.5em;\n","}\n","\n","#sk-container-id-2 label.sk-toggleable__label .caption {\n","  font-size: 0.6rem;\n","  font-weight: lighter;\n","  color: var(--sklearn-color-text-muted);\n","}\n","\n","#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n","  /* Arrow on the left of the label */\n","  content: \"‚ñ∏\";\n","  float: left;\n","  margin-right: 0.25em;\n","  color: var(--sklearn-color-icon);\n","}\n","\n","#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n","  color: var(--sklearn-color-text);\n","}\n","\n","/* Toggleable content - dropdown */\n","\n","#sk-container-id-2 div.sk-toggleable__content {\n","  max-height: 0;\n","  max-width: 0;\n","  overflow: hidden;\n","  text-align: left;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-2 div.sk-toggleable__content.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-2 div.sk-toggleable__content pre {\n","  margin: 0.2em;\n","  border-radius: 0.25em;\n","  color: var(--sklearn-color-text);\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n","  /* Expand drop-down */\n","  max-height: 200px;\n","  max-width: 100%;\n","  overflow: auto;\n","}\n","\n","#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n","  content: \"‚ñæ\";\n","}\n","\n","/* Pipeline/ColumnTransformer-specific style */\n","\n","#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator-specific style */\n","\n","/* Colorize estimator box */\n","#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n","#sk-container-id-2 div.sk-label label {\n","  /* The background is the default theme color */\n","  color: var(--sklearn-color-text-on-default-background);\n","}\n","\n","/* On hover, darken the color of the background */\n","#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","/* Label box, darken color on hover, fitted */\n","#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator label */\n","\n","#sk-container-id-2 div.sk-label label {\n","  font-family: monospace;\n","  font-weight: bold;\n","  display: inline-block;\n","  line-height: 1.2em;\n","}\n","\n","#sk-container-id-2 div.sk-label-container {\n","  text-align: center;\n","}\n","\n","/* Estimator-specific */\n","#sk-container-id-2 div.sk-estimator {\n","  font-family: monospace;\n","  border: 1px dotted var(--sklearn-color-border-box);\n","  border-radius: 0.25em;\n","  box-sizing: border-box;\n","  margin-bottom: 0.5em;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-2 div.sk-estimator.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","/* on hover */\n","#sk-container-id-2 div.sk-estimator:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-2 div.sk-estimator.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Specification for estimator info (e.g. \"i\" and \"?\") */\n","\n","/* Common style for \"i\" and \"?\" */\n","\n",".sk-estimator-doc-link,\n","a:link.sk-estimator-doc-link,\n","a:visited.sk-estimator-doc-link {\n","  float: right;\n","  font-size: smaller;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1em;\n","  height: 1em;\n","  width: 1em;\n","  text-decoration: none !important;\n","  margin-left: 0.5em;\n","  text-align: center;\n","  /* unfitted */\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-unfitted-level-1);\n","}\n","\n",".sk-estimator-doc-link.fitted,\n","a:link.sk-estimator-doc-link.fitted,\n","a:visited.sk-estimator-doc-link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","/* Span, style for the box shown on hovering the info icon */\n",".sk-estimator-doc-link span {\n","  display: none;\n","  z-index: 9999;\n","  position: relative;\n","  font-weight: normal;\n","  right: .2ex;\n","  padding: .5ex;\n","  margin: .5ex;\n","  width: min-content;\n","  min-width: 20ex;\n","  max-width: 50ex;\n","  color: var(--sklearn-color-text);\n","  box-shadow: 2pt 2pt 4pt #999;\n","  /* unfitted */\n","  background: var(--sklearn-color-unfitted-level-0);\n","  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n","}\n","\n",".sk-estimator-doc-link.fitted span {\n","  /* fitted */\n","  background: var(--sklearn-color-fitted-level-0);\n","  border: var(--sklearn-color-fitted-level-3);\n","}\n","\n",".sk-estimator-doc-link:hover span {\n","  display: block;\n","}\n","\n","/* \"?\"-specific style due to the `<a>` HTML tag */\n","\n","#sk-container-id-2 a.estimator_doc_link {\n","  float: right;\n","  font-size: 1rem;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1rem;\n","  height: 1rem;\n","  width: 1rem;\n","  text-decoration: none;\n","  /* unfitted */\n","  color: var(--sklearn-color-unfitted-level-1);\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","}\n","\n","#sk-container-id-2 a.estimator_doc_link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","#sk-container-id-2 a.estimator_doc_link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","}\n","</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(cv=10,\n","                   estimators=[(&#x27;rf&#x27;,\n","                                RandomForestClassifier(n_estimators=10,\n","                                                       random_state=42)),\n","                               (&#x27;knn&#x27;, KNeighborsClassifier(n_neighbors=10)),\n","                               (&#x27;gbdt&#x27;, GradientBoostingClassifier())],\n","                   final_estimator=LogisticRegression())</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StackingClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.StackingClassifier.html\">?<span>Documentation for StackingClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>StackingClassifier(cv=10,\n","                   estimators=[(&#x27;rf&#x27;,\n","                                RandomForestClassifier(n_estimators=10,\n","                                                       random_state=42)),\n","                               (&#x27;knn&#x27;, KNeighborsClassifier(n_neighbors=10)),\n","                               (&#x27;gbdt&#x27;, GradientBoostingClassifier())],\n","                   final_estimator=LogisticRegression())</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(n_estimators=10, random_state=42)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>knn</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>KNeighborsClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\">?<span>Documentation for KNeighborsClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>KNeighborsClassifier(n_neighbors=10)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>gbdt</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GradientBoostingClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\">?<span>Documentation for GradientBoostingClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>GradientBoostingClassifier()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["y_pred = clf.predict(X_test)"],"metadata":{"id":"DScTbQjBf-FZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","accuracy_score(y_test,y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2yZ3MEDsgBya","executionInfo":{"status":"ok","timestamp":1771934352816,"user_tz":-330,"elapsed":19,"user":{"displayName":"Arnav Tomar","userId":"05362157737552244045"}},"outputId":"4c60445a-4c8b-46c7-803c-36cda240397b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.956140350877193"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":[],"metadata":{"id":"3-OwGLVGgESr"},"execution_count":null,"outputs":[]}]}