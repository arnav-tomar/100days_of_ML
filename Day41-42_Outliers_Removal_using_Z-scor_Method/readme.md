# Outliers in Machine Learning â€” Final Complete Notes (Detection & Treatment)

*(This file consolidates **all concepts**, including the latest diagram:  
Z-score, IQR-based filtering, Percentile method, Winsorization)*

---

## 1. What are Outliers?

Outliers are observations that lie **abnormally far** from the majority of data points.

They:
- violate expected distribution
- distort statistical measures
- disproportionately impact ML models

Example:  
CGPA mostly in **6â€“9**, one value = **1.2 or 9.9**

---

## 2. Why Outliers Occur

- Data entry errors (extra zero, wrong unit)
- Measurement/sensor errors
- Sampling bias
- Natural rare events (fraud, defects)

ğŸ‘‰ Treatment depends on **why** the outlier exists.

---

## 3. When Are Outliers Dangerous?

### Dangerous when:
- Dataset is small
- Algorithm is distance- or mean-based
- Model assumes Gaussian distribution
- Loss = squared error

### Not dangerous when:
- Rare events are meaningful
- Using robust or tree-based models
- Task = anomaly detection

---

## 4. Effect of Outliers on ML Algorithms

### Statistical impact

| Metric | Effect |
|------|-------|
| Mean | Highly influenced |
| Variance | Inflated |
| Std Dev | Inflated |
| Correlation | Misleading |
| Median | Robust |
| IQR | Robust |

---

### Algorithm-wise effect

- **Linear / Logistic Regression** â†’ unstable coefficients
- **KNN** â†’ distance distortion
- **K-Means** â†’ centroid shift
- **PCA** â†’ components dominated
- **Tree models** â†’ least affected

---

## 5. How to Detect Outliers?

Detection depends on **distribution type**.

---

## 6. Techniques for Outlier Detection & Removal âœ… (As in Diagram)

---

## 6.1 Z-Score Treatment (Normal Distribution)

### Assumption
- Data is normally distributed

### Formula
\[
z = \frac{x - \mu}{\sigma}
\]

### Rule
\[
|z| > 3 \Rightarrow \text{Outlier}
\]

Based on **68â€“95â€“99.7 rule**:
- 99.7% data lies within Â±3Ïƒ

âœ… Simple & fast  
âŒ Fails for skewed data  

Use only when distribution â‰ˆ Gaussian.

---

## 6.2 IQR-Based Filtering âœ… (Most Used)

### Step 1: Compute
\[
IQR = Q_3 - Q_1
\]

### Step 2: Set bounds
\[
Lower = Q_1 - 1.5 \times IQR
\]
\[
Upper = Q_3 + 1.5 \times IQR
\]

Values outside bounds â†’ outliers

âœ… Robust to skew  
âœ… No distribution assumption  
âœ… Industry standard

---

## 6.3 Percentile Method âœ…

### Idea
- Treat extreme percentiles as outliers

Example:
- Values below 1st percentile
- Values above 99th percentile

Variants:
- 5â€“95
- 2.5â€“97.5

âœ… Simple  
âœ… Works for skewed data  
âŒ Cutoffs are arbitrary

Used heavily in finance & business datasets.

---

## 6.4 Winsorization (Capping) âœ…

### Idea
- Do **not delete** outliers
- Replace with boundary thresholds

Example:
Before: 1, 2, 3, 4, 100
After : 1, 2, 3, 4, 10 (capped)


Equivalent to:
- Percentile-based capping
- IQR-based capping

âœ… Preserves data size  
âœ… Limits extreme influence  
âœ… Better than trimming

---

## 7. Trimming (Removal)

- Completely remove outliers

âœ… Simple  
âŒ Data loss  
âŒ Dangerous if outliers are valid

Use only when:
- Large dataset
- Confirmed noise

---

## 8. Converting Outliers to Missing Values

- Replace extreme values with `NaN`
- Apply imputation later (median / ML)

âœ… Useful when data reliability is low  
âŒ Needs careful justification

---

## 9. Discretization (Binning)

Convert numeric values into ranges.

Example:
90â€“100 â†’ High
70â€“90 â†’ Medium


âœ… Reduces dominance of extremes  
âœ… Useful for tree & rule-based models  
âŒ Loses precision

---

## 10. Transformations

Used when outliers arise due to skewness.

- Log transform
- Square-root
- Boxâ€“Cox

âœ… Compresses large values  
âœ… Reduces skew  

---

## 11. Robust Scaling

Uses **median & IQR**:

\[
x' = \frac{x - Median}{IQR}
\]

âœ… Resistant to outliers  
âœ… Recommended before linear models

---

## 12. Model-Based Handling

Choose robust models instead of modifying data.

| Model | Robust |
|----|----|
| Random Forest | âœ… |
| XGBoost | âœ… |
| Huber Regression | âœ… |
| Quantile Regression | âœ… |

---

## 13. Outliers vs Anomalies

| Outliers | Anomalies |
|------|------|
| Statistical extremes | Behavioral extremes |
| Often noise | Often signal |
| May be removed | Must be detected |

Fraud detection focuses on **anomalies**, not removal.

---

## 14. Best Practices (Must Remember)

- Never blindly remove outliers
- Identify source first
- Normal data â†’ Z-score
- Skewed data â†’ IQR / Percentile
- Prefer capping over trimming
- Compare model performance before & after handling

---

## 15. Interview Golden Lines

- *Z-score works only for normal distributions.*
- *IQR is robust to skewness.*
- *Capping preserves data while controlling influence.*
- *Tree models handle outliers naturally.*
- *Outliers are dangerous only when they distort learning.*

---

## âœ… Final Summary

- Outliers are extreme deviations
- Detection methods:
  - Z-score
  - IQR
  - Percentile
- Treatment methods:
  - Trimming
  - Winsorization (capping)
  - Missing value strategy
  - Discretization
  - Transformations
  - Robust models
- No single best method â€” context matters
