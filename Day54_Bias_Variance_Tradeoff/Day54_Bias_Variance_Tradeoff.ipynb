{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN/ahjKs9+K/UIRXHanhECk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Model Selection, Underfitting, Overfitting, and the Bias–Variance Tradeoff\n","\n","---\n","\n","## 1. What Does “Best Model” Mean?\n","\n","A **best model** is **NOT** the model that fits training data perfectly.\n","\n","A best model is one that:\n","- Learns the true underlying pattern\n","- Performs well on **unseen data**\n","- Generalizes beyond training samples\n","\n","Formally, we want to minimize **generalization error**, not training error.\n","\n","---\n","\n","## 2. Model Complexity\n","\n","Model complexity refers to:\n","- Number of parameters\n","- Flexibility of the model\n","- Ability to fit complicated patterns\n","\n","Examples:\n","- Linear regression → low complexity\n","- Polynomial regression (high degree) → high complexity\n","- Deep neural networks → very high complexity\n","\n","---\n","\n","## 3. Underfitting\n","\n","### Definition\n","\n","A model **underfits** when it is **too simple** to capture the true relationship in data.\n","\n","---\n","\n","### Mathematical View\n","\n","True relationship:\n","$$\n","y = f(x)\n","$$\n","\n","Model approximation:\n","$$\n","\\hat{y} = g(x)\n","$$\n","\n","If:\n","$$\n","g(x) \\neq f(x)\n","$$\n","\n","because the model is too simple → **underfitting**\n","\n","---\n","\n","### Characteristics of Underfitting\n","\n","- High training error\n","- High test error\n","- Model ignores important patterns\n","- Bias is high\n","\n","---\n","\n","### Example\n","\n","Trying to fit a straight line to quadratic data:\n","$$\n","y = 3x^2 + 2x + 1\n","$$\n","\n","Using:\n","$$\n","y = \\beta_0 + \\beta_1 x\n","$$\n","\n","This **cannot work**, no matter how much data you have.\n","\n","---\n","\n","## 4. Overfitting\n","\n","### Definition\n","\n","A model **overfits** when it learns:\n","- Noise\n","- Random fluctuations\n","- Training-specific patterns\n","\n","instead of the true underlying function.\n","\n","---\n","\n","### Mathematical View\n","\n","Model fits:\n","$$\n","y = f(x) + \\epsilon\n","$$\n","\n","instead of:\n","$$\n","y = f(x)\n","$$\n","\n","where:\n","$$\n","\\epsilon = \\text{noise}\n","$$\n","\n","---\n","\n","### Characteristics of Overfitting\n","\n","- Very low training error\n","- High test error\n","- Model becomes unstable\n","- Variance is high\n","\n","---\n","\n","### Example\n","\n","Using a very high-degree polynomial:\n","\n","$$\n","y = \\beta_0 + \\beta_1 x + \\beta_2 x^2 + \\dots + \\beta_{30} x^{30}\n","$$\n","\n","The curve:\n","- Passes through almost every training point\n","- Fails badly on new data\n","\n","---\n","\n","## 5. Bias–Variance Decomposition\n","\n","Expected prediction error can be decomposed as:\n","\n","$$\n","\\text{Error} = \\text{Bias}^2 + \\text{Variance} + \\text{Irreducible Error}\n","$$\n","\n","---\n","\n","### Bias\n","\n","Bias measures:\n","$$\n","\\text{How far the average model prediction is from the true function}\n","$$\n","\n","High bias → underfitting\n","\n","---\n","\n","### Variance\n","\n","Variance measures:\n","$$\n","\\text{How much the model prediction changes with different training data}\n","$$\n","\n","High variance → overfitting\n","\n","---\n","\n","### Irreducible Error\n","\n","Caused by:\n","- Measurement noise\n","- Randomness in data\n","- Cannot be eliminated\n","\n","---\n","\n","## 6. Bias–Variance Tradeoff\n","\n","As model complexity increases:\n","\n","- Bias ↓\n","- Variance ↑\n","\n","As model complexity decreases:\n","\n","- Bias ↑\n","- Variance ↓\n","\n","There exists an **optimal complexity** where total error is minimum.\n","\n","---\n","\n","## 7. Graphical Intuition (Conceptual)\n","\n","| Model Type | Bias | Variance | Fit |\n","|-----------|------|----------|-----|\n","| Too Simple | High | Low | Underfitting |\n","| Optimal | Balanced | Balanced | Best |\n","| Too Complex | Low | High | Overfitting |\n","\n","---\n","\n","## 8. Why Training Accuracy Is Misleading\n","\n","A model can achieve:\n","$$\n","100\\% \\text{ training accuracy}\n","$$\n","\n","and still be **useless**.\n","\n","Reason:\n","$$\n","\\text{Training error} \\neq \\text{Generalization error}\n","$$\n","\n","---\n","\n","## 9. How to Choose the Right Model\n","\n","### Correct Approach\n","\n","1. Split data:\n","   - Training set\n","   - Validation set\n","   - Test set\n","\n","2. Train models with different complexity\n","\n","3. Compare **validation error**\n","\n","4. Select model with minimum validation error\n","\n","---\n","\n","## 10. Cross-Validation (Brief)\n","\n","Instead of one split:\n","\n","- Split data into K folds\n","- Train on K−1 folds\n","- Validate on remaining fold\n","- Repeat K times\n","\n","Final error:\n","$$\n","\\text{Average validation error}\n","$$\n","\n","---\n","\n","## 11. Why Simple Models Often Win\n","\n","Reasons:\n","- Less variance\n","- More stable\n","- Easier to interpret\n","- Generalize better on small data\n","\n","Rule of thumb:\n","\n","$$\n","\\text{Choose the simplest model that works}\n","$$\n","\n","---\n","\n","## 12. Practical Insight from the Lecture\n","\n","- Complex models look impressive\n","- Simple models work reliably\n","- Overfitting is more dangerous than underfitting in exams and production\n","\n","---\n","\n","## 13. Exam-Ready One-Line Definitions\n","\n","**Underfitting**  \n","> Model is too simple to learn the data pattern.\n","\n","**Overfitting**  \n","> Model fits noise instead of the true relationship.\n","\n","**Bias–Variance Tradeoff**  \n","> Increasing model complexity reduces bias but increases variance.\n","\n","---\n","\n","## 14. Final Takeaway\n","\n","The goal of machine learning is **not perfection on training data**.\n","\n","The real goal is:\n","\n","$$\n","\\text{Good performance on unseen data}\n","$$\n","\n","A balanced model beats a flashy one every time.\n","\n","---\n"],"metadata":{"id":"LkQvw-yE6ndl"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"fT1VM6Uj6dUe"},"outputs":[],"source":[]}]}